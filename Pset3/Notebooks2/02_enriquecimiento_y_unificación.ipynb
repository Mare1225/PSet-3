{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da42573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark import SparkConf\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0dec5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"net.snowflake:snowflake-jdbc:3.24.2,net.snowflake:spark-snowflake_2.12:3.1.2\") #1. Que antes de empezar tiene que descargar bibliotecas y paquetes externos y otros de snowflake(como supo este man que habia que hacer esa conexion?)\n",
    "conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.broadcastTimeout\", \"36000\")  # 10 minutos\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate() #Obtiene una SparkSession existente si ya hay una en ejecución y si no crea una nueva "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"/home/jovyan/work/.env\")\n",
    "\n",
    "sfOptions = { #Es un diccionario de Python que está reuniendo todos los parámetros necesarios para que el conector Spark-Snowflake (que configuraste en tu SparkConf anterior) sepa dónde y cómo conectarse a Snowflake.\n",
    "    \"sfURL\": os.getenv(\"URL\"),\n",
    "    \"sfDatabase\": os.getenv(\"DB\"),\n",
    "    \"sfSchema\": \"RAW\",\n",
    "    \"sfWarehouse\": os.getenv(\"WAREHOUSE\"),\n",
    "    \"sfRole\": os.getenv(\"ROLE\"),\n",
    "    \"sfUser\": os.getenv(\"USER\"),\n",
    "    \"sfPassword\": os.getenv(\"PASSWORD\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d93a607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfOptions = { #Es un diccionario de Python que está reuniendo todos los parámetros necesarios para que el conector Spark-Snowflake (que configuraste en tu SparkConf anterior) sepa dónde y cómo conectarse a Snowflake.\n",
    "    \"sfURL\" : \"TLZAPUN-PKC06603.snowflakecomputing.com\",\n",
    "    \"sfDatabase\" : \"NY_TAXI\",\n",
    "    \"sfSchema\" : \"RAW\",\n",
    "    \"sfWarehouse\" :\"COMPUTE_WH\",\n",
    "    \"sfRole\" : \"ACCOUNTADMIN\",\n",
    "    \"sfUser\" : \"MARE122510\",\n",
    "    \"sfPassword\" : \"MyTurnEra2025100%\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8a1e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_payment_type_label(df):\n",
    "      return df.withColumn(\"PAYMENT_TYPE_LABEL\",\n",
    "          F.when(F.col(\"PAYMENT_TYPE\") == 1, \"Credit card\")\n",
    "           .when(F.col(\"PAYMENT_TYPE\") == 2, \"Cash\")\n",
    "           .when(F.col(\"PAYMENT_TYPE\") == 3, \"No charge\")\n",
    "           .when(F.col(\"PAYMENT_TYPE\") == 4, \"Dispute\")\n",
    "           .when(F.col(\"PAYMENT_TYPE\") == 5, \"Unknown\")\n",
    "           .when(F.col(\"PAYMENT_TYPE\") == 6, \"Voided trip\")\n",
    "           .otherwise(\"Other\")\n",
    "      )\n",
    "\n",
    "  # ⚡ Reemplazar rate_code_udf con CASE WHEN nativo\n",
    "def add_ratecode_label(df):\n",
    "      return df.withColumn(\"RATECODE_LABEL\",\n",
    "          F.when(F.col(\"RATECODEID\") == 1, \"Standard\")\n",
    "           .when(F.col(\"RATECODEID\") == 2, \"JFK\")\n",
    "           .when(F.col(\"RATECODEID\") == 3, \"Newark\")\n",
    "           .when(F.col(\"RATECODEID\") == 4, \"Nassau or Westchester\")\n",
    "           .when(F.col(\"RATECODEID\") == 5, \"Negotiated fare\")\n",
    "           .when(F.col(\"RATECODEID\") == 6, \"Group ride\")\n",
    "           .otherwise(\"Other\")\n",
    "      )\n",
    "\n",
    "  # ⚡ Reemplazar vendor_udf con CASE WHEN nativo\n",
    "def add_vendor_label(df):\n",
    "      return df.withColumn(\"VENDOR_LABEL\",\n",
    "          F.when(F.col(\"VENDORID\") == 1, \"CMT\")\n",
    "           .when(F.col(\"VENDORID\") == 2, \"VeriFone\")\n",
    "           .otherwise(\"Other\")\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "081dce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the main trip data (from the RAW schema)\n",
    "df_yellow = spark.read \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions) \\\n",
    "    .option(\"dbtable\", \"YELLOW_TRIPS\") \\\n",
    "    .load()\\\n",
    "    .withColumn(\"SERVICE_TYPE\", F.lit(\"Yellow\"))\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc42096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions) \\\n",
    "    .option(\"dbtable\", \"GREEN_TRIPS\") \\\n",
    "    .load()\\\n",
    "    .withColumn(\"SERVICE_TYPE\", F.lit(\"Green\"))\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99a15435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_unificado = df_yellow.unionByName(df_green, allowMissingColumns=True)\\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "feb46e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the Taxi Zones data (from the RAW schema)\n",
    "df_zones = spark.read \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions) \\\n",
    "    .option(\"dbtable\", \"TAXI_ZONES\") \\\n",
    "    .load()\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78b53db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize zone columns for joining (important to avoid case issues in Spark)\n",
    "df_zones = df_zones.select(\n",
    "    F.col(\"LocationID\").alias(\"ZONE_ID\"),\n",
    "    F.col(\"Borough\").alias(\"BOROUGH_NAME\"),\n",
    "    F.col(\"Zone\").alias(\"ZONE_NAME\")\n",
    ")\\\n",
    ".cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa3e9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched = df_trips_unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd7aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new target schema (STAGE)\n",
    "sfOptions_stage = sfOptions.copy()\n",
    "sfOptions_stage[\"sfSchema\"] = \"STAGE\" \n",
    "# NOTE: Ensure the 'STAGE' schema exists in Snowflake before running the write operation.\n",
    "\n",
    "# a. Integrate Taxi Zones (Join)\n",
    "# Join for Pickup Location\n",
    "df_zones_broadcast = F.broadcast(df_zones)\n",
    "\n",
    "  # Join optimizado para pickup (con broadcast hint)\n",
    "df_enriched = df_trips_unificado.alias(\"trips\") \\\n",
    "      .join(df_zones_broadcast.alias(\"pu\"),\n",
    "            F.col(\"trips.PULOCATIONID\") == F.col(\"pu.ZONE_ID\"),\n",
    "            \"left\") \\\n",
    "      .withColumnRenamed(\"BOROUGH_NAME\", \"PU_BOROUGH\") \\\n",
    "      .withColumnRenamed(\"ZONE_NAME\", \"PU_ZONE\") \\\n",
    "      .drop(\"pu.ZONE_ID\")\n",
    "\n",
    "  # Join optimizado para dropoff (con broadcast hint)\n",
    "df_enriched = df_enriched.alias(\"trips\") \\\n",
    "      .join(df_zones_broadcast.alias(\"do\"),\n",
    "            F.col(\"trips.DOLOCATIONID\") == F.col(\"do.ZONE_ID\"),\n",
    "            \"left\") \\\n",
    "      .withColumnRenamed(\"BOROUGH_NAME\", \"DO_BOROUGH\") \\\n",
    "      .withColumnRenamed(\"ZONE_NAME\", \"DO_ZONE\") \\\n",
    "      .drop(\"do.ZONE_ID\")\n",
    "\n",
    "  # Aplicar todas las transformaciones de una vez (más eficiente)\n",
    "df_enriched = add_payment_type_label(df_enriched)\n",
    "df_enriched = add_ratecode_label(df_enriched)\n",
    "df_enriched = add_vendor_label(df_enriched)\n",
    "\n",
    "  # Cache el resultado final\n",
    "df_enriched = df_enriched.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d991bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"VENDORID\", \"VENDOR_LABEL\", \"SERVICE_TYPE\", \n",
    "    F.coalesce(F.col(\"TPEP_PICKUP_DATETIME\"), F.col(\"LPEP_PICKUP_DATETIME\")).alias(\"PICKUP_DATETIME\"),\n",
    "    F.coalesce(F.col(\"TPEP_DROPOFF_DATETIME\"), F.col(\"LPEP_DROPOFF_DATETIME\")).alias(\"DROPOFF_DATETIME\"),\n",
    "    \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \n",
    "    \"RATECODEID\", \"RATECODE_LABEL\",\n",
    "    \"PULOCATIONID\", \"PU_BOROUGH\", \"PU_ZONE\", \n",
    "    \"DOLOCATIONID\", \"DO_BOROUGH\", \"DO_ZONE\",\n",
    "    \"PAYMENT_TYPE\", \"PAYMENT_TYPE_LABEL\", \n",
    "    # Financial fields\n",
    "    \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\", \n",
    "    \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\", \"CONGESTION_SURCHARGE\", \"AIRPORT_FEE\", \n",
    "    \"CBD_CONGESTION_FEE\", \n",
    "    # Metadata\n",
    "    \"RUN_ID\", \"SOURCE_YEAR\", \"SOURCE_MONTH\", \"INGESTED_AT_UTC\", \"SOURCE_PATH\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22634a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_stage = df_enriched.select(*final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to the STAGE schema in Snowflake\n",
    "table_name_stage = \"TRIPS_ENRICHED\"\n",
    "\n",
    "df_final_stage.write \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions_stage) \\\n",
    "    .option(\"dbtable\", table_name_stage) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
