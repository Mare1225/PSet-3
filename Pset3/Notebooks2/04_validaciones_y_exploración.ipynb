{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbe9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark import SparkConf\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"net.snowflake:snowflake-jdbc:3.24.2,net.snowflake:spark-snowflake_2.12:3.1.2\") #1. Que antes de empezar tiene que descargar bibliotecas y paquetes externos y otros de snowflake(como supo este man que habia que hacer esa conexion?)\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate() #Obtiene una SparkSession existente si ya hay una en ejecución y si no crea una nueva "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4601bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfOptions = { #Es un diccionario de Python que está reuniendo todos los parámetros necesarios para que el conector Spark-Snowflake (que configuraste en tu SparkConf anterior) sepa dónde y cómo conectarse a Snowflake.\n",
    "    \"sfURL\" : \"TLZAPUN-PKC06603.snowflakecomputing.com\",\n",
    "    \"sfDatabase\" : \"NY_TAXI\",\n",
    "    \"sfSchema\" : \"ANALYTICS\",\n",
    "    \"sfWarehouse\" :\"COMPUTE_WH\",\n",
    "    \"sfRole\" : \"ACCOUNTADMIN\",\n",
    "    \"sfUser\" : \"MARE122510\",\n",
    "    \"sfPassword\" : \"MyTurnEra2025100%\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
