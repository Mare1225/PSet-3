{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf3a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5822a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"net.snowflake:snowflake-jdbc:3.24.2,net.snowflake:spark-snowflake_2.12:3.1.2\")\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"/home/jovyan/work/.env\")\n",
    "\n",
    "sfOptions = {\n",
    "    \"sfURL\": os.getenv(\"URL\"),\n",
    "    \"sfDatabase\": os.getenv(\"DB\"),\n",
    "    \"sfSchema\": \"RAW\",\n",
    "    \"sfWarehouse\": os.getenv(\"WAREHOUSE\"),\n",
    "    \"sfRole\": os.getenv(\"ROLE\"),\n",
    "    \"sfUser\": os.getenv(\"USER\"),\n",
    "    \"sfPassword\": os.getenv(\"PASSWORD\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796897f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025']\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "services = ['green', 'yellow'] #agregar 'yellow' si se desea procesar también\n",
    "\n",
    "for service in services:\n",
    "    if service == 'yellow':\n",
    "        ordered_cols = [\n",
    "        \"VENDORID\", \"TPEP_PICKUP_DATETIME\", \"TPEP_DROPOFF_DATETIME\",\n",
    "        \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \"RATECODEID\",\n",
    "        \"STORE_AND_FWD_FLAG\", \"PULOCATIONID\", \"DOLOCATIONID\",\n",
    "        \"PAYMENT_TYPE\", \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\",\n",
    "        \"TIP_AMOUNT\", \"TOLLS_AMOUNT\", \"IMPROVEMENT_SURCHARGE\",\n",
    "        \"TOTAL_AMOUNT\", \"CONGESTION_SURCHARGE\", \"AIRPORT_FEE\",\n",
    "        \"CBD_CONGESTION_FEE\",  # ¡asegúrate de este orden exacto!\n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\"\n",
    "        ]\n",
    "    else:\n",
    "        ordered_cols = [\n",
    "        \"VENDORID\", \"LPEP_PICKUP_DATETIME\", \"LPEP_DROPOFF_DATETIME\",\n",
    "        \"STORE_AND_FWD_FLAG\", \"RATECODEID\",\n",
    "        \"PULOCATIONID\", \"DOLOCATIONID\", \"PASSENGER_COUNT\", \"TRIP_DISTANCE\",\n",
    "        \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "        \"EHAIL_FEE\", \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\",\n",
    "        \"PAYMENT_TYPE\", \"TRIP_TYPE\", \"CONGESTION_SURCHARGE\",\n",
    "        \"CBD_CONGESTION_FEE\",  \n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\"\n",
    "        ]\n",
    "    for year in years:\n",
    "        if year == '2025':\n",
    "            months = ['01', '02', '03', '04', '05', '06', '07']\n",
    "        for month in months:\n",
    "            if service == 'yellow':\n",
    "                timestamp_columns = ['TPEP_PICKUP_DATETIME', 'TPEP_DROPOFF_DATETIME']\n",
    "            else:\n",
    "                timestamp_columns = ['LPEP_PICKUP_DATETIME', 'LPEP_DROPOFF_DATETIME']\n",
    "\n",
    "\n",
    "            url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{service}_tripdata_{year}-{month}.parquet\"\n",
    "            response = requests.head(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"No existe: {url}\")\n",
    "                continue\n",
    "            print(f\"Procesando {service}: {year}-{month}\")\n",
    "\n",
    "            # Descargar archivo temporalmente\n",
    "            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".parquet\")\n",
    "            tmp_path = tmp_file.name\n",
    "            tmp_file.close()\n",
    "            r = requests.get(url)\n",
    "            with open(tmp_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "            # Leer archivo con Spark\n",
    "            df = spark.read.parquet(tmp_path)\n",
    "            print(f\"Archivo {url} cargado en DataFrame\")\n",
    "\n",
    "            # Crear run_id para indempotencia\n",
    "            run_id = f\"run_{year}_{month}\"\n",
    "\n",
    "            # Agregar metadatos\n",
    "            df = (\n",
    "                df.withColumn(\"RUN_ID\", F.lit(run_id))\n",
    "                  .withColumn(\"SERVICE_TYPE\", F.lit(service))\n",
    "                  .withColumn(\"SOURCE_YEAR\", F.lit(int(year)))\n",
    "                  .withColumn(\"SOURCE_MONTH\", F.lit(int(month)))\n",
    "                  .withColumn(\"INGESTED_AT_UTC\", F.to_utc_timestamp(F.current_timestamp(), \"America/Guayaquil\")) #En UTC\n",
    "                  .withColumn(\"SOURCE_PATH\", F.lit(url))\n",
    "            )\n",
    "\n",
    "            # Normalizar nombres de columnas a mayusculas\n",
    "            df = df.toDF(*[c.upper() for c in df.columns])\n",
    "            print(\"Metadatos agregados\")\n",
    "\n",
    "            # Convertir columnas de timestamp\n",
    "            for col_name in timestamp_columns:\n",
    "                if col_name in df.columns:\n",
    "                    df = df.withColumn(col_name, F.col(col_name).cast(\"timestamp\"))\n",
    "\n",
    "            # Escribir en Snowflake\n",
    "            table_name = f\"{service.upper()}_TRIPS\"\n",
    "\n",
    "            # COLUMNA NUEVA DE ANIOS POSTERIORES\n",
    "            if \"CBD_CONGESTION_FEE\" not in df.columns:\n",
    "                # Si no está, agrega la columna con valor None (o un valor predeterminado)\n",
    "                df = df.withColumn(\"CBD_CONGESTION_FEE\", F.lit(None).cast(T.DoubleType()))\n",
    "\n",
    "            # Eliminar registros previos de la misma ejecución (idempotencia)\n",
    "            spark.read \\\n",
    "                .format(\"snowflake\") \\\n",
    "                .options(**sfOptions) \\\n",
    "                .option(\"query\", f\"DELETE FROM {table_name} WHERE RUN_ID = '{run_id}'\") \\\n",
    "                .load()\n",
    "            \n",
    "            # Reordenar columnas según ordered_cols para que no de error\n",
    "            df = df.select([c for c in ordered_cols if c in df.columns])\n",
    "\n",
    "                \n",
    "\n",
    "            df.write \\\n",
    "                .format(\"snowflake\") \\\n",
    "                .options(**sfOptions) \\\n",
    "                .option(\"dbtable\", table_name) \\\n",
    "                .mode(\"append\") \\\n",
    "                .save() \n",
    "            print(f\"Datos de {service} para {year}-{month} cargados en Snowflake\")\n",
    "\n",
    "            # Eliminar archivo temporal\n",
    "            os.remove(tmp_path) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c4ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv cargado en DataFrame\n"
     ]
    }
   ],
   "source": [
    "# cargar taxi zones\n",
    "url_zones = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "# Descargar archivo temporalmente\n",
    "tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "tmp_path = tmp_file.name\n",
    "tmp_file.close()\n",
    "r = requests.get(url_zones)\n",
    "with open(tmp_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "df_zones = spark.read.csv(tmp_path, header=True, inferSchema=True)\n",
    "print(f\"Archivo {url_zones} cargado en DataFrame\")\n",
    "\n",
    "\n",
    "df_zones.write \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions) \\\n",
    "    .option(\"dbtable\", \"TAXI_ZONES\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
