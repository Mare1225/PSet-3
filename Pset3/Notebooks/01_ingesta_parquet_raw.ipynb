{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf3a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b5822a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"net.snowflake:snowflake-jdbc:3.24.2,net.snowflake:spark-snowflake_2.12:3.1.2\") #1. Que antes de empezar tiene que descargar bibliotecas y paquetes externos y otros de snowflake(como supo este man que habia que hacer esa conexion?)\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate() #Obtiene una SparkSession existente si ya hay una en ejecución y si no crea una nueva "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv(dotenv_path=\"/home/jovyan/work/.env\")\n",
    "\n",
    "sfOptions = { #Es un diccionario de Python que está reuniendo todos los parámetros necesarios para que el conector Spark-Snowflake (que configuraste en tu SparkConf anterior) sepa dónde y cómo conectarse a Snowflake.\n",
    "    \"sfURL\" : \"TLZAPUN-PKC06603.snowflakecomputing.com\",\n",
    "    \"sfDatabase\" : \"NY_TAXI\",\n",
    "    \"sfSchema\" : \"RAW\",\n",
    "    \"sfWarehouse\" :\"COMPUTE_WH\",\n",
    "    \"sfRole\" : \"ACCOUNTADMIN\",\n",
    "    \"sfUser\" : \"MARE122510\",\n",
    "    \"sfPassword\" : \"MyTurnEra2025100%\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "kjzs3f1xxnh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando conexión a Snowflake...\n",
      "✓ Conexión a Snowflake exitosa\n",
      "+-------------------+\n",
      "|\"CURRENT_VERSION()\"|\n",
      "+-------------------+\n",
      "|             9.32.1|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Probar conexión a Snowflake\n",
    "print(\"Probando conexión a Snowflake...\")\n",
    "try:\n",
    "    # Crear un DataFrame de prueba\n",
    "    test_df = spark.createDataFrame([(\"test\",)], [\"col1\"])\n",
    "    \n",
    "    # Intentar leer desde Snowflake para verificar conexión\n",
    "    test_read = spark.read \\\n",
    "        .format(\"snowflake\") \\\n",
    "        .options(**sfOptions) \\\n",
    "        .option(\"query\", \"SELECT CURRENT_VERSION()\") \\\n",
    "        .load()\n",
    "    \n",
    "    print(\"✓ Conexión a Snowflake exitosa\")\n",
    "    test_read.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error conectando a Snowflake: {str(e)}\")\n",
    "    print(\"Verificar credenciales y configuración de red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a000e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (41.0.4)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (23.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (4.15.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.20.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (0.13.3)\n",
      "Requirement already satisfied: boto3>=1.24 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.40.55)\n",
      "Requirement already satisfied: botocore>=1.24 in /opt/conda/lib/python3.11/site-packages (from snowflake-connector-python) (1.40.55)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.24->snowflake-connector-python) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.24->snowflake-connector-python) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore>=1.24->snowflake-connector-python) (2.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.1.0->snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.1.0->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5102269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando yellow: 2022-01\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-01 cargados en Snowflake\n",
      "Procesando yellow: 2022-02\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-02 cargados en Snowflake\n",
      "Procesando yellow: 2022-03\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-03 cargados en Snowflake\n",
      "Procesando yellow: 2022-04\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-04 cargados en Snowflake\n",
      "Procesando yellow: 2022-05\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-05 cargados en Snowflake\n",
      "Procesando yellow: 2022-06\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-06 cargados en Snowflake\n",
      "Procesando yellow: 2022-07\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-07 cargados en Snowflake\n",
      "Procesando yellow: 2022-08\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-08 cargados en Snowflake\n",
      "Procesando yellow: 2022-09\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-09 cargados en Snowflake\n",
      "Procesando yellow: 2022-10\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-10 cargados en Snowflake\n",
      "Procesando yellow: 2022-11\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-11 cargados en Snowflake\n",
      "Procesando yellow: 2022-12\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2022-12 cargados en Snowflake\n",
      "Procesando yellow: 2023-01\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-01 cargados en Snowflake\n",
      "Procesando yellow: 2023-02\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-02 cargados en Snowflake\n",
      "Procesando yellow: 2023-03\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-03 cargados en Snowflake\n",
      "Procesando yellow: 2023-04\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-04 cargados en Snowflake\n",
      "Procesando yellow: 2023-05\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-05 cargados en Snowflake\n",
      "Procesando yellow: 2023-06\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-06 cargados en Snowflake\n",
      "Procesando yellow: 2023-07\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-07 cargados en Snowflake\n",
      "Procesando yellow: 2023-08\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-08 cargados en Snowflake\n",
      "Procesando yellow: 2023-09\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-09 cargados en Snowflake\n",
      "Procesando yellow: 2023-10\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-10 cargados en Snowflake\n",
      "Procesando yellow: 2023-11\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-11 cargados en Snowflake\n",
      "Procesando yellow: 2023-12\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2023-12 cargados en Snowflake\n",
      "Procesando yellow: 2024-01\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-01 cargados en Snowflake\n",
      "Procesando yellow: 2024-02\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-02 cargados en Snowflake\n",
      "Procesando yellow: 2024-03\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-03 cargados en Snowflake\n",
      "Procesando yellow: 2024-04\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-04 cargados en Snowflake\n",
      "Procesando yellow: 2024-05\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-05 cargados en Snowflake\n",
      "Procesando yellow: 2024-06\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-06 cargados en Snowflake\n",
      "Procesando yellow: 2024-07\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-07 cargados en Snowflake\n",
      "Procesando yellow: 2024-08\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-08 cargados en Snowflake\n",
      "Procesando yellow: 2024-09\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-09.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-09 cargados en Snowflake\n",
      "Procesando yellow: 2024-10\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-10 cargados en Snowflake\n",
      "Procesando yellow: 2024-11\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-11 cargados en Snowflake\n",
      "Procesando yellow: 2024-12\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2024-12 cargados en Snowflake\n",
      "Procesando yellow: 2025-01\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-01 cargados en Snowflake\n",
      "Procesando yellow: 2025-02\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-02.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-02 cargados en Snowflake\n",
      "Procesando yellow: 2025-03\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-03 cargados en Snowflake\n",
      "Procesando yellow: 2025-04\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-04.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-04 cargados en Snowflake\n",
      "Procesando yellow: 2025-05\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-05.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-05 cargados en Snowflake\n",
      "Procesando yellow: 2025-06\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-06.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-06 cargados en Snowflake\n",
      "Procesando yellow: 2025-07\n",
      "Archivo https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-07.parquet cargado en DataFrame\n",
      "Metadatos agregados\n",
      "Datos de yellow para 2025-07 cargados en Snowflake\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import snowflake.connector\n",
    "import os\n",
    "\n",
    "years = list(range(2015,2025))\n",
    "months = [ '01', '02', '03', '04','05', '06', '07', '08', '09', '10', '11', '12']\n",
    "services = ['yellow'] #agregar 'yellow' si se desea procesar también\n",
    "\n",
    "for service in services:\n",
    "    if service == 'yellow':\n",
    "        ordered_cols = [\n",
    "        \"VENDORID\", \"TPEP_PICKUP_DATETIME\", \"TPEP_DROPOFF_DATETIME\",\n",
    "        \"PASSENGER_COUNT\", \"TRIP_DISTANCE\", \"RATECODEID\",\n",
    "        \"STORE_AND_FWD_FLAG\", \"PULOCATIONID\", \"DOLOCATIONID\",\n",
    "        \"PAYMENT_TYPE\", \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\",\n",
    "        \"TIP_AMOUNT\", \"TOLLS_AMOUNT\", \"IMPROVEMENT_SURCHARGE\",\n",
    "        \"TOTAL_AMOUNT\", \"CONGESTION_SURCHARGE\", \"AIRPORT_FEE\",\n",
    "        \"CBD_CONGESTION_FEE\", \n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\"\n",
    "        ]\n",
    "    else:\n",
    "        ordered_cols = [\n",
    "        \"VENDORID\", \"LPEP_PICKUP_DATETIME\", \"LPEP_DROPOFF_DATETIME\",\n",
    "        \"STORE_AND_FWD_FLAG\", \"RATECODEID\",\n",
    "        \"PULOCATIONID\", \"DOLOCATIONID\", \"PASSENGER_COUNT\", \"TRIP_DISTANCE\",\n",
    "        \"FARE_AMOUNT\", \"EXTRA\", \"MTA_TAX\", \"TIP_AMOUNT\", \"TOLLS_AMOUNT\",\n",
    "        \"EHAIL_FEE\", \"IMPROVEMENT_SURCHARGE\", \"TOTAL_AMOUNT\",\n",
    "        \"PAYMENT_TYPE\", \"TRIP_TYPE\", \"CONGESTION_SURCHARGE\",\n",
    "        \"CBD_CONGESTION_FEE\",  \n",
    "        \"RUN_ID\", \"SERVICE_TYPE\", \"SOURCE_YEAR\", \"SOURCE_MONTH\",\n",
    "        \"INGESTED_AT_UTC\", \"SOURCE_PATH\"\n",
    "        ]\n",
    "    for year in years:\n",
    "        if year == '2025':\n",
    "            months = ['01', '02', '03', '04', '05', '06', '07']\n",
    "        for month in months:\n",
    "            if service == 'yellow':\n",
    "                timestamp_columns = ['TPEP_PICKUP_DATETIME', 'TPEP_DROPOFF_DATETIME']\n",
    "            else:\n",
    "                timestamp_columns = ['LPEP_PICKUP_DATETIME', 'LPEP_DROPOFF_DATETIME']\n",
    "\n",
    "\n",
    "            url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{service}_tripdata_{year}-{month}.parquet\"\n",
    "            response = requests.head(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"No existe: {url}\")\n",
    "                continue\n",
    "            print(f\"Procesando {service}: {year}-{month}\")\n",
    "\n",
    "            # Descargar archivo temporalmente\n",
    "            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".parquet\")\n",
    "            tmp_path = tmp_file.name\n",
    "            tmp_file.close()\n",
    "            r = requests.get(url)\n",
    "            with open(tmp_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "            # Leer archivo con Spark\n",
    "            df = spark.read.parquet(tmp_path)\n",
    "            print(f\"Archivo {url} cargado en DataFrame\")\n",
    "\n",
    "            # Crear run_id para indempotencia\n",
    "            run_id = f\"run_{year}_{month}\"\n",
    "\n",
    "            # Agregar metadatos\n",
    "            df = (\n",
    "                df.withColumn(\"RUN_ID\", F.lit(run_id))\n",
    "                  .withColumn(\"SERVICE_TYPE\", F.lit(service))\n",
    "                  .withColumn(\"SOURCE_YEAR\", F.lit(int(year)))\n",
    "                  .withColumn(\"SOURCE_MONTH\", F.lit(int(month)))\n",
    "                  .withColumn(\"INGESTED_AT_UTC\", F.to_utc_timestamp(F.current_timestamp(), \"America/Guayaquil\")) #En UTC\n",
    "                  .withColumn(\"SOURCE_PATH\", F.lit(url))\n",
    "            )\n",
    "\n",
    "            # Normalizar nombres de columnas a mayusculas\n",
    "            df = df.toDF(*[c.upper() for c in df.columns])\n",
    "            print(\"Metadatos agregados\")\n",
    "\n",
    "            # Convertir columnas de timestamp\n",
    "            for col_name in timestamp_columns:\n",
    "                if col_name in df.columns:\n",
    "                    df = df.withColumn(col_name, F.col(col_name).cast(\"timestamp\"))\n",
    "\n",
    "            # Escribir en Snowflake\n",
    "            table_name = f\"{service.upper()}_TRIPS\"\n",
    "\n",
    "            # COLUMNA NUEVA DE ANIOS POSTERIORES\n",
    "            if \"CBD_CONGESTION_FEE\" not in df.columns:\n",
    "                # Si no está, agrega la columna con valor None (o un valor predeterminado)\n",
    "                df = df.withColumn(\"CBD_CONGESTION_FEE\", F.lit(None).cast(T.DoubleType()))\n",
    "\n",
    "             #Eliminar registros previos de la misma ejecución (idempotencia)\n",
    "            spark.read \\\n",
    "                .format(\"snowflake\") \\\n",
    "                .options(**sfOptions) \\\n",
    "                .option(\"query\", f\"DELETE FROM {table_name} WHERE RUN_ID = '{run_id}'\") \\\n",
    "                .load()\n",
    "\n",
    "            \n",
    "            # Reordenar columnas según ordered_cols para que no de error\n",
    "            df = df.select([c for c in ordered_cols if c in df.columns])\n",
    "\n",
    "                \n",
    "\n",
    "            df.write \\\n",
    "                .format(\"snowflake\") \\\n",
    "                .options(**sfOptions) \\\n",
    "                .option(\"dbtable\", table_name) \\\n",
    "                .mode(\"append\") \\\n",
    "                .save() \n",
    "            print(f\"Datos de {service} para {year}-{month} cargados en Snowflake\")\n",
    "\n",
    "            # Eliminar archivo temporal\n",
    "            os.remove(tmp_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c4ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv cargado en DataFrame\n"
     ]
    }
   ],
   "source": [
    "# cargar taxi zones\n",
    "url_zones = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "# Descargar archivo temporalmente\n",
    "tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "tmp_path = tmp_file.name\n",
    "tmp_file.close()\n",
    "r = requests.get(url_zones)\n",
    "with open(tmp_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "df_zones = spark.read.csv(tmp_path, header=True, inferSchema=True)\n",
    "print(f\"Archivo {url_zones} cargado en DataFrame\")\n",
    "\n",
    "\n",
    "df_zones.write \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**sfOptions) \\\n",
    "    .option(\"dbtable\", \"TAXI_ZONES\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
